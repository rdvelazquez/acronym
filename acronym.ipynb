{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the misuse of acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating large documents with multiple authors and lots of jargon, acronyms are sometimes misused in a few ways:\n",
    "1. Used but not defined. (Ex. This report will be submitted to the EPA.)\n",
    "2. Used before being defined. (Ex. This report will be submitted to the EPA. The EPA (Environmental Protection Agency) will review the report.)\n",
    "3. Defined multiple times. (Ex. This report will be submitted to the EPA (Environmental Protection Agency). The EPA (Environmental Protection Agency) will review the report.)\n",
    "\n",
    "This notebook identifies instances of acronym misuse in a word document. Word's \"find\" function can then be used to assist in locating and correcting the instances of misuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = Document('Example Document.docx')\n",
    "text = ''\n",
    "for paragraph in document.paragraphs:\n",
    "    text += paragraph.text\n",
    "# Create a list of the individual words after removing punctuation.\n",
    "text_words = text.translate({ord(punc): None for punc in '.?!,:;\"\\''})\n",
    "text_words = text_words.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list suspected acronyms from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of words that are inclosed by parenthesis.\n",
    "words_parentheses_with_paren = [word for word in text_words if \n",
    "                                                    word.startswith('(') and\n",
    "                                                    word.endswith(')') and \n",
    "                                                    len(word) > 3]\n",
    "words_parentheses = [word.translate({ord(punc): None for punc in '()'}) for word in words_parentheses_with_paren]\n",
    "# Get a list of words that are all caps.\n",
    "text_words_cleaned = [word.translate({ord(punc): None for punc in '()'}) for word in text_words]\n",
    "words_all_caps = [word for word in text_words_cleaned if word.isupper()]\n",
    "# Get a list of suspected acronyms by combining the parentheses and all caps words\n",
    "suspected_acronyms = words_parentheses + words_all_caps\n",
    "suspected_acronyms = list(set(suspected_acronyms))\n",
    "# Remove some items that are not acronyms\n",
    "acronyms_to_be_removed = []\n",
    "for acronym in suspected_acronyms:\n",
    "    # No letters.\n",
    "    if not any(c.isalpha() for c in acronym):\n",
    "        acronyms_to_be_removed.append(acronym)\n",
    "    # Only one character.\n",
    "    if len(acronym) <= 1:\n",
    "        acronyms_to_be_removed.append(acronym)\n",
    "    # Sample/Area of Concern/Monitoring Well (Items specific to the environmental field that often include a hyphen).\n",
    "    if '-' in acronym:\n",
    "        acronyms_to_be_removed.append(acronym)\n",
    "    # TODO: Section header or all caps for another reason? TODO\n",
    "acronyms = list(set(suspected_acronyms) - set(acronyms_to_be_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe of summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acronym_stats = dict.fromkeys(acronyms)\n",
    "for key in acronym_stats:\n",
    "    acronym_stats[key] = {'defined': [], 'used': []}\n",
    "# Parenthesised.\n",
    "for key in acronym_stats:\n",
    "    loc = 0\n",
    "    for word in text_words:\n",
    "        parenthesised_key = '(' + key + ')'\n",
    "        if word == parenthesised_key:\n",
    "            acronym_stats[key]['defined'].append(loc)\n",
    "        loc += 1    \n",
    "# Abbreviated.\n",
    "for key in acronym_stats:\n",
    "    loc = 0\n",
    "    for word in text_words:\n",
    "        if word == key:\n",
    "            acronym_stats[key]['used'].append(loc)\n",
    "        loc += 1\n",
    "acronym_df = pd.DataFrame(acronym_stats).T\n",
    "acronym_df.index.name = 'acronym'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the acronyms that were misused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acronyms used before being defined: NAPL, RCRA\n",
      "\n",
      "\n",
      "Acronyms used but never defined: 25V, 2H+, AOC, EPA, GQS, II, IIA, ISCO, IT, ITRC, LSRP, NX, PA, SCC, SCC/SRS, SESC, SI/RI, SRS, VOC\n",
      "\n",
      "\n",
      "Acronyms defined more than once: UST\n"
     ]
    }
   ],
   "source": [
    "defined_multiple_times, never_defined, used_before_defined = [], [], []\n",
    "for index, row in acronym_df.iterrows():\n",
    "    if len(row['defined']) == 0:\n",
    "        never_defined.append(index)\n",
    "    elif min(row['used'], default=1000000) < min(row['defined'], default=0):\n",
    "        used_before_defined.append(index)\n",
    "    elif len(row['defined']) > 1:\n",
    "        defined_multiple_times.append(index)\n",
    "print('Acronyms used before being defined: ' + '%s' % ', '.join(map(str, used_before_defined)))\n",
    "print('\\n')\n",
    "print('Acronyms used but never defined: ' + '%s' % ', '.join(map(str, never_defined)))\n",
    "print('\\n')\n",
    "print('Acronyms defined more than once: ' + '%s' % ', '.join(map(str, defined_multiple_times)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
